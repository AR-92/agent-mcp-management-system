# Model Providers

## Overview

Strands supports multiple LLM providers to give you flexibility in choosing the best model for your use case.

## Amazon Bedrock

Integration with Amazon Bedrock for accessing foundation models with enterprise-level security and compliance.

## Anthropic

Support for Anthropic's Claude models with full safety and reliability features.

## LiteLLM

LiteLLM provider for unified access to multiple LLM providers through a single interface.

## llama.cpp

Local inference support using llama.cpp for running models on your own infrastructure.

## LlamaAPI

Integration with LlamaAPI for hosted Llama model inference.

## MistralAI

Support for MistralAI models and their unique capabilities.

## Ollama

Ollama provider for running open-source models locally.

## OpenAI

Integration with OpenAI's models including GPT-4, GPT-3.5, and newer models.

## SageMaker

Amazon SageMaker integration for custom model deployment and inference.

## Writer

Integration with Writer's AI models and services.

## Cohere

Support for Cohere's language models and embeddings.

## Custom Providers

Framework for integrating your own custom model providers with Strands.